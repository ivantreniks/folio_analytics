{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in /opt/conda/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: bleach>=3.1.1 in /opt/conda/lib/python3.9/site-packages (from swifter) (3.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.9/site-packages (from swifter) (7.6.3)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /opt/conda/lib/python3.9/site-packages (from swifter) (4.61.2)\n",
      "Requirement already satisfied: parso>0.4.0 in /opt/conda/lib/python3.9/site-packages (from swifter) (0.8.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from swifter) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /opt/conda/lib/python3.9/site-packages (from swifter) (5.9.5)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from swifter) (2.2.1)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in /opt/conda/lib/python3.9/site-packages (from swifter) (2023.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from bleach>=3.1.1->swifter) (21.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from bleach>=3.1.1->swifter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: click>=8.0 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.3)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (6.6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.9/site-packages (from dask[dataframe]>=2.10.0->swifter) (1.21.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (6.0.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (5.0.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (7.25.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (3.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->swifter) (3.5.2)\n",
      "Requirement already satisfied: debugpy>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.3.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1.12)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (49.6.0.post20210108)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (3.0.19)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (5.0.9)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.17.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->swifter) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.9/site-packages (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (22.1.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.11.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.7.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (3.0.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.10.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "!pip install pandas\n",
    "m = Mystem()\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "!pip install swifter\n",
    "import swifter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами данные о почти 160.000 комментариях, размеченные по  степени токсичности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что отсутствует баланс. При классификации попробуем сбалансировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    daww he matches this background colour im seem...\n",
       "2    hey man im really not trying to edit war its j...\n",
       "3    more i cant make any real suggestions on impro...\n",
       "4    you sir are my hero any chance you remember wh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные в порядок - уберем лишние символы и сделаем текст с маленькой буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf1878c23f34404954a23f1c510b07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 57s, sys: 1min 59s, total: 22min 57s\n",
      "Wall time: 23min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize(text):\n",
    "    #text=text.split()\n",
    "    lemmatized_output = ' '.join(lmtzr.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text))\n",
    "    return lemmatized_output\n",
    "                                  \n",
    "\n",
    "\n",
    "\n",
    "#lemmatize('this is an ambulance calls michaels maggots nuggets feet mice')\n",
    "data['lemm_text'] = data['text'].swifter.apply(lemmatize)\n",
    "\n",
    "\n",
    "# data = data.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем\n",
    "\n",
    "Эта ячейка достаточно долго запускалась, особенно локально. Как с этим бороться? Можно ли как то ускорить процесс?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data['toxic']\n",
    "features=data['lemm_text']\n",
    "\n",
    "\n",
    "train_features,test_features,train_target,test_target=train_test_split(features,target,random_state=12345,test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим на две выборки, в соотношении 3:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_train = count_tf_idf.fit_transform(train_features)\n",
    "tf_test = count_tf_idf.transform(test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекратим данные в вектор для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C': list(range(1,14,3)),'class_weight':[None,'balanced']}]\n",
    "model=LogisticRegression(random_state=12345,max_iter=450)\n",
    "grid_cv = GridSearchCV(model, param_grid=param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END .............................C=1, class_weight=None; total time=  54.4s\n",
      "[CV] END .............................C=1, class_weight=None; total time=  53.7s\n",
      "[CV] END .............................C=1, class_weight=None; total time=  56.3s\n",
      "[CV] END .........................C=1, class_weight=balanced; total time= 1.1min\n",
      "[CV] END .........................C=1, class_weight=balanced; total time=  27.1s\n",
      "[CV] END .........................C=1, class_weight=balanced; total time=  31.5s\n",
      "[CV] END .............................C=4, class_weight=None; total time= 1.5min\n",
      "[CV] END .............................C=4, class_weight=None; total time= 1.2min\n",
      "[CV] END .............................C=4, class_weight=None; total time= 1.2min\n",
      "[CV] END .........................C=4, class_weight=balanced; total time= 1.2min\n",
      "[CV] END .........................C=4, class_weight=balanced; total time= 1.9min\n",
      "[CV] END .........................C=4, class_weight=balanced; total time= 1.5min\n",
      "[CV] END .............................C=7, class_weight=None; total time= 1.7min\n",
      "[CV] END .............................C=7, class_weight=None; total time= 1.9min\n",
      "[CV] END .............................C=7, class_weight=None; total time= 1.9min\n",
      "[CV] END .........................C=7, class_weight=balanced; total time= 1.9min\n",
      "[CV] END .........................C=7, class_weight=balanced; total time= 2.2min\n",
      "[CV] END .........................C=7, class_weight=balanced; total time= 1.6min\n",
      "[CV] END ............................C=10, class_weight=None; total time= 1.9min\n",
      "[CV] END ............................C=10, class_weight=None; total time= 1.8min\n",
      "[CV] END ............................C=10, class_weight=None; total time= 1.8min\n",
      "[CV] END ........................C=10, class_weight=balanced; total time= 1.6min\n",
      "[CV] END ........................C=10, class_weight=balanced; total time= 1.9min\n",
      "[CV] END ........................C=10, class_weight=balanced; total time= 1.6min\n",
      "[CV] END ............................C=13, class_weight=None; total time= 1.6min\n",
      "[CV] END ............................C=13, class_weight=None; total time= 2.2min\n",
      "[CV] END ............................C=13, class_weight=None; total time= 2.4min\n",
      "[CV] END ........................C=13, class_weight=balanced; total time= 2.3min\n",
      "[CV] END ........................C=13, class_weight=balanced; total time= 2.3min\n",
      "[CV] END ........................C=13, class_weight=balanced; total time= 2.1min\n",
      "Best parameters: {'C': 7, 'class_weight': 'balanced'}\n",
      "Best score: 0.7543645437882561\n",
      "CPU times: user 20min 58s, sys: 29min 22s, total: 50min 20s\n",
      "Wall time: 50min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_grid = grid_cv.fit(tf_train, train_target)\n",
    "print('Best parameters:', grid_cv.best_params_)\n",
    "print('Best score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь на случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_forest = {\n",
    "    'n_estimators': list(range(50,151,50)),\n",
    "    'max_depth':[5,10],\n",
    "    'max_features' : list(range(1,15, 2))}\n",
    "\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=12345)\n",
    "                                 \n",
    "grid = GridSearchCV(model_forest, param_grid=params_forest, scoring='f1', cv=3, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n",
      "[CV] END .......max_depth=5, max_features=1, n_estimators=50; total time=   1.1s\n",
      "[CV] END .......max_depth=5, max_features=1, n_estimators=50; total time=   1.1s\n",
      "[CV] END .......max_depth=5, max_features=1, n_estimators=50; total time=   1.2s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=100; total time=   2.0s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=100; total time=   2.0s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=150; total time=   3.1s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=150; total time=   3.2s\n",
      "[CV] END ......max_depth=5, max_features=1, n_estimators=150; total time=   3.1s\n",
      "[CV] END .......max_depth=5, max_features=3, n_estimators=50; total time=   1.2s\n",
      "[CV] END .......max_depth=5, max_features=3, n_estimators=50; total time=   1.2s\n",
      "[CV] END .......max_depth=5, max_features=3, n_estimators=50; total time=   1.3s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=100; total time=   2.4s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=100; total time=   2.4s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=100; total time=   2.3s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=150; total time=   3.6s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=150; total time=   3.5s\n",
      "[CV] END ......max_depth=5, max_features=3, n_estimators=150; total time=   3.5s\n",
      "[CV] END .......max_depth=5, max_features=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END .......max_depth=5, max_features=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END .......max_depth=5, max_features=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=150; total time=   3.8s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=150; total time=   3.9s\n",
      "[CV] END ......max_depth=5, max_features=5, n_estimators=150; total time=   3.8s\n",
      "[CV] END .......max_depth=5, max_features=7, n_estimators=50; total time=   1.5s\n",
      "[CV] END .......max_depth=5, max_features=7, n_estimators=50; total time=   1.3s\n",
      "[CV] END .......max_depth=5, max_features=7, n_estimators=50; total time=   1.4s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=150; total time=   4.0s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=150; total time=   3.9s\n",
      "[CV] END ......max_depth=5, max_features=7, n_estimators=150; total time=   4.0s\n",
      "[CV] END .......max_depth=5, max_features=9, n_estimators=50; total time=   1.4s\n",
      "[CV] END .......max_depth=5, max_features=9, n_estimators=50; total time=   1.4s\n",
      "[CV] END .......max_depth=5, max_features=9, n_estimators=50; total time=   1.3s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=100; total time=   2.8s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=100; total time=   2.8s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=100; total time=   2.9s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=150; total time=   4.4s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=150; total time=   4.3s\n",
      "[CV] END ......max_depth=5, max_features=9, n_estimators=150; total time=   4.2s\n",
      "[CV] END ......max_depth=5, max_features=11, n_estimators=50; total time=   1.6s\n",
      "[CV] END ......max_depth=5, max_features=11, n_estimators=50; total time=   1.7s\n",
      "[CV] END ......max_depth=5, max_features=11, n_estimators=50; total time=   1.7s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=100; total time=   3.0s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=100; total time=   2.9s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=150; total time=   4.5s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=150; total time=   4.4s\n",
      "[CV] END .....max_depth=5, max_features=11, n_estimators=150; total time=   4.3s\n",
      "[CV] END ......max_depth=5, max_features=13, n_estimators=50; total time=   1.5s\n",
      "[CV] END ......max_depth=5, max_features=13, n_estimators=50; total time=   1.6s\n",
      "[CV] END ......max_depth=5, max_features=13, n_estimators=50; total time=   1.5s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=100; total time=   3.0s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=100; total time=   2.9s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=150; total time=   4.3s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=150; total time=   4.6s\n",
      "[CV] END .....max_depth=5, max_features=13, n_estimators=150; total time=   4.5s\n",
      "[CV] END ......max_depth=10, max_features=1, n_estimators=50; total time=   1.3s\n",
      "[CV] END ......max_depth=10, max_features=1, n_estimators=50; total time=   1.3s\n",
      "[CV] END ......max_depth=10, max_features=1, n_estimators=50; total time=   1.3s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=150; total time=   3.8s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=150; total time=   3.9s\n",
      "[CV] END .....max_depth=10, max_features=1, n_estimators=150; total time=   3.8s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   1.7s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   1.7s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   1.7s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   3.3s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=150; total time=   4.7s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=150; total time=   4.7s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=150; total time=   4.6s\n",
      "[CV] END ......max_depth=10, max_features=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END ......max_depth=10, max_features=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END ......max_depth=10, max_features=5, n_estimators=50; total time=   1.9s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=150; total time=   5.3s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=150; total time=   5.3s\n",
      "[CV] END .....max_depth=10, max_features=5, n_estimators=150; total time=   5.4s\n",
      "[CV] END ......max_depth=10, max_features=7, n_estimators=50; total time=   2.1s\n",
      "[CV] END ......max_depth=10, max_features=7, n_estimators=50; total time=   2.0s\n",
      "[CV] END ......max_depth=10, max_features=7, n_estimators=50; total time=   2.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=100; total time=   4.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=100; total time=   4.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=100; total time=   4.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=150; total time=   6.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=150; total time=   6.0s\n",
      "[CV] END .....max_depth=10, max_features=7, n_estimators=150; total time=   6.1s\n",
      "[CV] END ......max_depth=10, max_features=9, n_estimators=50; total time=   2.3s\n",
      "[CV] END ......max_depth=10, max_features=9, n_estimators=50; total time=   2.2s\n",
      "[CV] END ......max_depth=10, max_features=9, n_estimators=50; total time=   2.2s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=100; total time=   4.1s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=100; total time=   4.2s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=100; total time=   4.0s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=150; total time=   6.4s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=150; total time=   6.1s\n",
      "[CV] END .....max_depth=10, max_features=9, n_estimators=150; total time=   6.4s\n",
      "[CV] END .....max_depth=10, max_features=11, n_estimators=50; total time=   2.5s\n",
      "[CV] END .....max_depth=10, max_features=11, n_estimators=50; total time=   2.3s\n",
      "[CV] END .....max_depth=10, max_features=11, n_estimators=50; total time=   2.4s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=100; total time=   4.4s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=100; total time=   4.5s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=100; total time=   4.5s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=150; total time=   6.7s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=150; total time=   6.6s\n",
      "[CV] END ....max_depth=10, max_features=11, n_estimators=150; total time=   6.7s\n",
      "[CV] END .....max_depth=10, max_features=13, n_estimators=50; total time=   2.4s\n",
      "[CV] END .....max_depth=10, max_features=13, n_estimators=50; total time=   2.4s\n",
      "[CV] END .....max_depth=10, max_features=13, n_estimators=50; total time=   2.4s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=100; total time=   4.5s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=100; total time=   4.5s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=100; total time=   4.5s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=150; total time=   6.7s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=150; total time=   6.8s\n",
      "[CV] END ....max_depth=10, max_features=13, n_estimators=150; total time=   7.0s\n",
      "Best parameters: {'max_depth': 5, 'max_features': 1, 'n_estimators': 50}\n",
      "Best score: 0.0\n",
      "CPU times: user 6min 44s, sys: 3.65 s, total: 6min 47s\n",
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_grid = grid.fit(tf_train, train_target)\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятно, случайный лес вообще не подходит для классификации. Не будем его использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7649685174585005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C = 10, class_weight= 'balanced', max_iter=400)\n",
    "model.fit(tf_train, train_target)\n",
    "pred = model.predict(tf_test)\n",
    "f1_score(test_target, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВЫВОД**: таким образом, нам удалось выявить модель Логистической Регрессии для классификации токсичных комментариев, которая показала метрику F-1 Score выше, чем 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ИТОГИ ПРОЕКТА:**\n",
    "\n",
    "* данные импротированы, проверены на пропуски\n",
    "\n",
    "* проверили баланс классов, лемматизировали и токенизировали текст для обработки\n",
    "\n",
    "* разделили данные и векторизовали строки\n",
    "\n",
    "* рассмотрели модели логистической регрессии и случайного леса\n",
    "\n",
    "* **получили модель логистической регрессии с f1-score на уровне 0.77**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1845,
    "start_time": "2023-05-28T21:37:41.253Z"
   },
   {
    "duration": 198,
    "start_time": "2023-05-28T21:37:44.999Z"
   },
   {
    "duration": 3682,
    "start_time": "2023-05-28T21:37:54.401Z"
   },
   {
    "duration": 2722,
    "start_time": "2023-05-28T21:37:59.460Z"
   },
   {
    "duration": 120314,
    "start_time": "2023-05-28T21:38:02.902Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T21:40:20.902Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-28T21:40:22.908Z"
   },
   {
    "duration": 7499,
    "start_time": "2023-05-28T21:40:24.596Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T21:40:51.496Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-28T21:40:53.101Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-28T21:41:09.670Z"
   },
   {
    "duration": 38,
    "start_time": "2023-05-28T21:41:10.999Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T21:41:26.920Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-28T21:41:28.286Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T21:42:36.325Z"
   },
   {
    "duration": 818237,
    "start_time": "2023-05-28T21:42:38.493Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-28T21:57:13.170Z"
   },
   {
    "duration": 53,
    "start_time": "2023-05-28T21:57:28.870Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-28T21:57:33.316Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-28T21:57:40.965Z"
   },
   {
    "duration": 364077,
    "start_time": "2023-05-28T21:57:43.865Z"
   },
   {
    "duration": 7125,
    "start_time": "2023-05-28T22:03:47.944Z"
   },
   {
    "duration": 141130,
    "start_time": "2023-05-28T22:04:06.100Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-28T22:08:09.098Z"
   },
   {
    "duration": 746,
    "start_time": "2023-05-28T22:08:10.296Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-28T22:08:12.109Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-28T22:08:29.522Z"
   },
   {
    "duration": 1423,
    "start_time": "2023-05-28T22:12:23.785Z"
   },
   {
    "duration": 843,
    "start_time": "2023-05-28T22:12:25.210Z"
   },
   {
    "duration": 26,
    "start_time": "2023-05-28T22:12:26.054Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-28T22:12:26.082Z"
   },
   {
    "duration": 2472,
    "start_time": "2023-05-28T22:12:26.096Z"
   },
   {
    "duration": 58438,
    "start_time": "2023-05-28T22:12:28.570Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-28T22:13:27.009Z"
   },
   {
    "duration": 64,
    "start_time": "2023-05-28T22:13:27.015Z"
   },
   {
    "duration": 7139,
    "start_time": "2023-05-28T22:13:27.081Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-28T22:13:34.222Z"
   },
   {
    "duration": 2489299,
    "start_time": "2023-05-28T22:13:34.234Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-28T22:55:03.535Z"
   },
   {
    "duration": 335054,
    "start_time": "2023-05-28T22:55:03.544Z"
   },
   {
    "duration": 134048,
    "start_time": "2023-05-28T23:00:38.600Z"
   },
   {
    "duration": 10239,
    "start_time": "2023-05-28T23:03:19.799Z"
   },
   {
    "duration": 125545,
    "start_time": "2023-05-28T23:03:32.101Z"
   },
   {
    "duration": 1701,
    "start_time": "2023-06-03T00:14:21.037Z"
   },
   {
    "duration": 2875,
    "start_time": "2023-06-03T00:14:22.741Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-03T00:14:25.618Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-03T00:14:27.535Z"
   },
   {
    "duration": 2951,
    "start_time": "2023-06-03T00:14:32.770Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-03T00:15:23.230Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-03T00:15:26.635Z"
   },
   {
    "duration": 127,
    "start_time": "2023-06-03T00:15:30.109Z"
   },
   {
    "duration": 32,
    "start_time": "2023-06-03T00:15:34.573Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-03T00:15:43.109Z"
   },
   {
    "duration": 192,
    "start_time": "2023-06-03T00:19:52.610Z"
   },
   {
    "duration": 1459,
    "start_time": "2023-06-03T00:22:05.749Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-03T00:22:18.515Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-03T00:28:09.069Z"
   },
   {
    "duration": 62,
    "start_time": "2023-06-03T00:28:54.740Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-03T00:29:10.988Z"
   },
   {
    "duration": 245,
    "start_time": "2023-06-03T00:29:23.291Z"
   },
   {
    "duration": 200,
    "start_time": "2023-06-03T00:29:40.510Z"
   },
   {
    "duration": 451,
    "start_time": "2023-06-03T00:30:20.492Z"
   },
   {
    "duration": 480,
    "start_time": "2023-06-03T00:30:54.950Z"
   },
   {
    "duration": 734,
    "start_time": "2023-06-03T00:31:05.790Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-03T00:31:34.476Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-03T00:31:38.897Z"
   },
   {
    "duration": 7583,
    "start_time": "2023-06-03T00:32:04.875Z"
   },
   {
    "duration": 124,
    "start_time": "2023-06-03T00:32:23.003Z"
   },
   {
    "duration": 75780,
    "start_time": "2023-06-03T00:33:41.594Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-03T00:34:57.377Z"
   },
   {
    "duration": 25172,
    "start_time": "2023-06-03T00:34:59.421Z"
   },
   {
    "duration": 2903,
    "start_time": "2023-06-03T00:35:43.867Z"
   },
   {
    "duration": 5590,
    "start_time": "2023-06-03T00:37:34.818Z"
   },
   {
    "duration": 8209,
    "start_time": "2023-06-03T00:38:52.713Z"
   },
   {
    "duration": 932,
    "start_time": "2023-06-03T00:39:21.272Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-03T00:39:22.417Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-03T00:39:23.800Z"
   },
   {
    "duration": 3002,
    "start_time": "2023-06-03T00:39:26.274Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-03T00:39:29.723Z"
   },
   {
    "duration": 1411773,
    "start_time": "2023-06-03T00:39:33.699Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-03T01:03:05.480Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-03T01:03:05.490Z"
   },
   {
    "duration": 8808,
    "start_time": "2023-06-03T01:03:05.542Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-03T01:03:14.351Z"
   },
   {
    "duration": 3025391,
    "start_time": "2023-06-03T01:03:14.358Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-03T01:53:39.751Z"
   },
   {
    "duration": 408764,
    "start_time": "2023-06-03T01:53:39.757Z"
   },
   {
    "duration": 126265,
    "start_time": "2023-06-03T02:00:28.523Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
